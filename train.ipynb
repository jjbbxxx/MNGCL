{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cee44-22c4-4fa3-8024-a9cc2a939772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import yaml\n",
    "from yaml import SafeLoader\n",
    "from time import perf_counter as t\n",
    "import numpy as np\n",
    "from mngcl import MNGCL\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "from gcn import GCN\n",
    "from torch_geometric.utils import dropout_adj\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8742848-ca5c-4f18-8a17-01478166763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffab43-8387-403a-b7c1-f26430dbc621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, loss, checkpoint_path=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "\n",
    "def load_label_single(path):\n",
    "    label = np.loadtxt(path + \"label_file-P-\"+cancerType+\".txt\")\n",
    "    Y = torch.tensor(label).type(torch.FloatTensor).to(device).unsqueeze(1)\n",
    "    label_pos = np.loadtxt(path + \"pos-\"+cancerType+\".txt\", dtype=int)\n",
    "    label_neg = np.loadtxt(path + \"neg.txt\", dtype=int)\n",
    "    return Y, label_pos, label_neg\n",
    "\n",
    "def sample_division_single(pos_label, neg_label, l, l1, l2, i):\n",
    "    # pos_label：Positive sample index\n",
    "    # neg_label：Negative sample index\n",
    "    # l：number of genes\n",
    "    # l1：Number of positive samples\n",
    "    # l2：number of negative samples\n",
    "    # i：number of folds\n",
    "    pos_test = pos_label[i * l1:(i + 1) * l1]\n",
    "    pos_train = list(set(pos_label) - set(pos_test))\n",
    "    neg_test = neg_label[i * l2:(i + 1) * l2]\n",
    "    neg_train = list(set(neg_label) - set(neg_test))\n",
    "    indexs1 = [False] * l\n",
    "    indexs2 = [False] * l\n",
    "    for j in range(len(pos_train)):\n",
    "        indexs1[pos_train[j]] = True\n",
    "    for j in range(len(neg_train)):\n",
    "        indexs1[neg_train[j]] = True\n",
    "    for j in range(len(pos_test)):\n",
    "        indexs2[pos_test[j]] = True\n",
    "    for j in range(len(neg_test)):\n",
    "        indexs2[neg_test[j]] = True\n",
    "    tr_mask = torch.from_numpy(np.array(indexs1))\n",
    "    te_mask = torch.from_numpy(np.array(indexs2))\n",
    "    return tr_mask, te_mask\n",
    "\n",
    "def train(mask):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x = data.x\n",
    "    ppiAdj_index = ppiAdj.coalesce().indices()\n",
    "    pathAdj_index = pathAdj.coalesce().indices()\n",
    "    goAdj_index = goAdj.coalesce().indices()\n",
    "    #feature mask\n",
    "    x_1 = F.dropout(x, drop_feature_rate_1)\n",
    "    x_2 = F.dropout(x, drop_feature_rate_2)\n",
    "    x_3 = F.dropout(x, drop_feature_rate_3)\n",
    "    #edge dropout\n",
    "    ppiAdj_index = dropout_adj(ppiAdj_index, p=drop_edge_rate_1, force_undirected=True)[0]\n",
    "    pathAdj_index = dropout_adj(pathAdj_index, p=drop_edge_rate_2, force_undirected=True)[0]\n",
    "    goAdj_index = dropout_adj(goAdj_index, p=drop_edge_rate_3, force_undirected=True)[0]\n",
    "    pred1,pred2,pred3,_,conloss= model(ppiAdj_index,pathAdj_index,goAdj_index,x_1,x_2,x_3)\n",
    "    loss1 = F.binary_cross_entropy_with_logits(pred1[mask], Y[mask])\n",
    "    loss2 = F.binary_cross_entropy_with_logits(pred2[mask], Y[mask])\n",
    "    loss3 = F.binary_cross_entropy_with_logits(pred3[mask], Y[mask])\n",
    "    loss = 0.55*conloss+0.15*loss1+0.15*loss2+0.15*loss3\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def LogReg(train_x, train_y, test_x):\n",
    "    regr = linear_model.LogisticRegression(max_iter=10000)\n",
    "    regr.fit(train_x, train_y.ravel())\n",
    "    pre = regr.predict_proba(test_x)\n",
    "    pre = pre[:,1]\n",
    "    return pre\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask1, mask2):\n",
    "    model.eval()\n",
    "    ppiAdj_index = ppiAdj.coalesce().indices()\n",
    "    pathAdj_index = pathAdj.coalesce().indices()\n",
    "    goAdj_index = goAdj.coalesce().indices()\n",
    "    _,_,_,emb,_ = model(ppiAdj_index,pathAdj_index,goAdj_index,data.x,data.x,data.x)\n",
    "    train_x = torch.sigmoid(emb[mask1]).cpu().detach().numpy()\n",
    "    train_y = Y[mask1].cpu().numpy()\n",
    "    test_x = torch.sigmoid(emb[mask2]).cpu().detach().numpy()\n",
    "    Yn = Y[mask2].cpu().numpy()\n",
    "    pred = LogReg(train_x, train_y, test_x)\n",
    "    precision, recall, _thresholds = metrics.precision_recall_curve(Yn, pred)\n",
    "    area = metrics.auc(recall, precision)\n",
    "    return metrics.roc_auc_score(Yn, pred), area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c68cc-395d-4975-aad6-88b4e3aeb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default='CPDB')\n",
    "    parser.add_argument('--cancer_type', type=str, default='pan-cancer')\n",
    "    parser.add_argument('--gpu_id', type=int, default=0)\n",
    "    parser.add_argument('--config', type=str, default='config.yaml')\n",
    "    args = parser.parse_args()\n",
    "    config = yaml.load(open(args.config), Loader=SafeLoader)[args.dataset]\n",
    "    dataPath = \"data/\"+args.dataset+\"/\"\n",
    "    cancerType = args.cancer_type\n",
    "    seed = config['seed']\n",
    "    LR = config['LR']\n",
    "    drop_edge_rate_1 = config['drop_edge_rate_1']\n",
    "    drop_edge_rate_2 = config['drop_edge_rate_2']\n",
    "    drop_edge_rate_3 = config['drop_edge_rate_3']\n",
    "    drop_feature_rate_1 = config['drop_feature_rate_1']\n",
    "    drop_feature_rate_2 = config['drop_feature_rate_2']\n",
    "    drop_feature_rate_3 = config['drop_feature_rate_3']\n",
    "    tau = config['tau']\n",
    "    EPOCH = config['EPOCH']\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    data = torch.load(dataPath+args.dataset+\"_data.pkl\")\n",
    "    device = torch.device('cpu')\n",
    "    data = data.to(device)\n",
    "\n",
    "    Y = torch.tensor(np.logical_or(data.y, data.y_te)).type(torch.FloatTensor).to(device)\n",
    "    y_all = np.logical_or(data.y, data.y_te)\n",
    "    mask_all = np.logical_or(data.mask, data.mask_te)\n",
    "\n",
    "    if cancerType=='pan-cancer':\n",
    "        data.x = data.x[:,:48]\n",
    "    else:\n",
    "        cancerType_dict = {\n",
    "                          'kirc':[0,16,32],\n",
    "                          'brca':[1,17,33],\n",
    "                          'prad':[3,19,35],\n",
    "                          'stad':[4,20,36],\n",
    "                          'hnsc':[5,21,37],\n",
    "                          'luad':[6,22,38],\n",
    "                          'thca':[7,23,39],\n",
    "                          'blca':[8,24,40],\n",
    "                          'esca':[9,25,41],\n",
    "                          'lihc':[10,26,42],\n",
    "                          'ucec':[11,27,43],\n",
    "                          'coad':[12,28,44],\n",
    "                          'lusc':[13,29,45],\n",
    "                          'cesc':[14,30,46],\n",
    "                          'kirp':[15,31,47]\n",
    "                                  }\n",
    "        data.x = data.x[:, cancerType_dict[cancerType]]\n",
    "    print(data.x)\n",
    "\n",
    "    # node2VEC feature\n",
    "    dataz = torch.load(dataPath + \"Str_feature.pkl\", map_location='cpu')  # 加载到CPU\n",
    "    dataz = dataz.to(device)  # 将其移动到CPU\n",
    "    data.x = torch.cat((data.x, dataz), 1)  # 64D feature\n",
    "\n",
    "    # 加载其他矩阵\n",
    "    ppiAdj = torch.load(dataPath + 'ppi.pkl', map_location='cpu')  # 加载到CPU\n",
    "    ppiAdj_self = torch.load(dataPath + 'ppi_selfloop.pkl', map_location='cpu')  # 加载到CPU\n",
    "    pathAdj = torch.load(dataPath + 'pathway_SimMatrix.pkl', map_location='cpu')  # 加载到CPU\n",
    "    goAdj = torch.load(dataPath + 'GO_SimMatrix.pkl', map_location='cpu')  # 加载到CPU\n",
    "\n",
    "    # 转换稀疏矩阵为稠密矩阵\n",
    "    pos = ppiAdj_self.to_dense()  # 转换为稠密矩阵\n",
    "\n",
    "    if args.dataset =='CPDB':\n",
    "        with open(dataPath+\"k_sets.pkl\", 'rb') as handle:\n",
    "            k_sets = pickle.load(handle)\n",
    "    else:\n",
    "        k_sets = torch.load(dataPath+\"k_sets.pkl\")\n",
    "\n",
    "    AUC = np.zeros(shape=(cross_val, 5))\n",
    "    AUPR = np.zeros(shape=(cross_val, 5))\n",
    "    train_time = t()\n",
    "    #pan-cancer\n",
    "    print(\"---------Pan-cancer Train begin--------\")\n",
    "    for i in range(cross_val):\n",
    "        for cv_run in range(5):\n",
    "            print(\"----------------------- i: %d, cv_run: %d -------------------------\" % (i + 1, cv_run + 1))\n",
    "            start = t()\n",
    "            y_tr, y_te, tr_mask, te_mask = k_sets[i][cv_run]\n",
    "            gcn = GCN(64,300,100).to(device)\n",
    "            model = MNGCL( gnn=gcn,\n",
    "                           pos=pos,\n",
    "                           tau=tau,\n",
    "                           gnn_outsize=100,\n",
    "                           projection_hidden_size=300,\n",
    "                           projection_size=100\n",
    "                       ).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "            for train_epoch in range(1,EPOCH):\n",
    "                loss = train(tr_mask)\n",
    "                AUC[i][cv_run], AUPR[i][cv_run] = test(tr_mask,te_mask)\n",
    "                print(f'(T) | Epoch={train_epoch:03d}, loss={loss:.4f},AUC={AUC[i][cv_run]:.4f}, AUPR={AUPR[i][cv_run]:.4f}')\n",
    "            np.savetxt(\"./AUC.txt\", AUC, delimiter=\"\\t\")\n",
    "            np.savetxt(\"./AUPR.txt\", AUPR, delimiter=\"\\t\")\n",
    "            now = t()\n",
    "            print(\"this cv_run spend {:.1f}  s\".format(now - start))\n",
    "        print(AUC[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335e093-2780-4ad9-aac2-0184429a664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #specific cancer\n",
    "    '''print(\"---------\"+cancerType+\" cancer Train begin--------\")\n",
    "    path = dataPath+\"Specific cancer/\"\n",
    "    for i in range(cross_val):\n",
    "        label, label_pos, label_neg = load_label_single(path)\n",
    "        random.shuffle(label_pos)\n",
    "        random.shuffle(label_neg)\n",
    "        l = len(label)\n",
    "        l1 = int(len(label_pos)/5)\n",
    "        l2 = int(len(label_neg)/5)\n",
    "        Y = label\n",
    "        for cv_run in range(5):\n",
    "            print(\"----------------------- i: %d, cv_run: %d -------------------------\" % (i + 1, cv_run + 1))\n",
    "            start = t()\n",
    "            tr_mask, te_mask = sample_division_single(label_pos, label_neg, l, l1, l2, cv_run)\n",
    "            gcn = GCN(19,150,50).to(device)\n",
    "            model = MNGCL(gnn=gcn,\n",
    "                           pos=pos,\n",
    "                           tau=tau,\n",
    "                           gnn_outsize=50,\n",
    "                           projection_hidden_size=150,\n",
    "                           projection_size=50\n",
    "                       ).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "            for train_epoch in range(1,EPOCH):\n",
    "                loss = train(tr_mask)\n",
    "                AUC[i][cv_run], AUPR[i][cv_run] = test(tr_mask,te_mask)      \n",
    "                print(f'(T) | Epoch={train_epoch:03d}, loss={loss:.4f},AUC={AUC[i][cv_run]:.4f}, AUPR={AUPR[i][cv_run]:.4f}')\n",
    "            \n",
    "            np.savetxt(\"./AUC.txt\", AUC, delimiter=\"\\t\")\n",
    "            np.savetxt(\"./AUPR.txt\", AUPR, delimiter=\"\\t\")\n",
    "            now = t()\n",
    "           \n",
    "            print(\"this cv_run spend {:.2f}  s\".format(now - start))\n",
    "        print(AUC[i].mean())\n",
    "        print(AUPR[i].mean())'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
